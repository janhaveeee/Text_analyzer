{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "AI-Powered Smart Text Analyzer:\n",
    "A cutting-edge NLP tool that summarizes, paraphrases, analyzes sentiment, extracts keywords, classifies topics, evaluates readability, and generates questions\u2014all in one place!"
   ],
   "metadata": {
    "id": "DzBsgny2SzU7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the PEGASUS Model and Tokenizer\n"
   ],
   "metadata": {
    "id": "cuNttRzRS5AJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ],
   "metadata": {
    "id": "rbweyqxSS0cD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing the PEGASUS Summarization Model"
   ],
   "metadata": {
    "id": "60oYYhPWS-q1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "\n",
    "# Load model with low RAM usage\n",
    "MODEL_NAME = \"google/pegasus-large\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(MODEL_NAME, torch_dtype=torch.float16)\n",
    "model.to(\"cpu\")  # Use \"cuda\" if you have GPU\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GKTH03rlENg",
    "outputId": "6f6220a4-7488-4b91-ebe6-d544f66aa8af"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Text Summarization Function"
   ],
   "metadata": {
    "id": "JjJbt01nTAaq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def summarize_text(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=80,  # Keeps summary concise\n",
    "            min_length=50,  # Prevents overly short output\n",
    "            length_penalty=1.3,  # Makes sure it doesn't favor longer phrases\n",
    "            num_beams=7,  # Slightly higher for better diversity\n",
    "            no_repeat_ngram_size=3,  # Prevents repetition\n",
    "            early_stopping=True,\n",
    "            repetition_penalty=1.15  # Avoids over-favoring specific parts\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
   ],
   "metadata": {
    "id": "zUL7rcgy5itX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " Generating a Summary with PEGASUS"
   ],
   "metadata": {
    "id": "8kN33_61THW2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"\"\"Artificial Intelligence (AI) is transforming industries by automating tasks,\n",
    "improving efficiency, and generating insights. From healthcare to finance, AI-powered solutions\n",
    "are revolutionizing the way we work and live. However, ethical concerns around data privacy\n",
    "and algorithmic bias remain significant challenges in AI development. Researchers and policymakers\n",
    "are working together to ensure AI benefits society while minimizing risks.\"\"\"\n",
    "\n",
    "summary = summarize_text(text)\n",
    "print(\"Summarized Text:\\n\", summary)\n"
   ],
   "metadata": {
    "id": "kYykdDaS42e3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "455df75c-fdfa-4d5d-b296-80ef327e1f7e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install yake"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IiipPSV4PkxS",
    "outputId": "e4b68378-e3e7-45c0-ff55-6154184e903b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " Keyword Extraction using YAKE"
   ],
   "metadata": {
    "id": "-IWCSfjcTP0w"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import yake\n",
    "\n",
    "def extract_keywords(text, num_keywords=5):\n",
    "    \"\"\"Extract important keywords from the text.\"\"\"\n",
    "    kw_extractor = yake.KeywordExtractor()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    return [kw[0] for kw in keywords[:num_keywords]]\n",
    "\n",
    "# Example usage\n",
    "keywords = extract_keywords(text)\n",
    "print(\"Keywords:\", keywords)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vcZaVO4nPiht",
    "outputId": "877b8a7d-85a9-4a94-e046-84e7222005ab"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sentiment Analysis using TextBlob\n"
   ],
   "metadata": {
    "id": "I-JgfkSgTVxx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"Determine sentiment polarity of the text.\"\"\"\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    if sentiment > 0:\n",
    "        return \"Positive\"\n",
    "    elif sentiment < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Example usage\n",
    "sentiment = analyze_sentiment(text)\n",
    "print(\"Sentiment:\", sentiment)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-wM1ZSlPpRL",
    "outputId": "e0e50c96-44cd-49e4-9a9f-226452b44a37"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pip install transformers\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RaCyJPpzPuZe",
    "outputId": "79f76e55-b1b4-40dc-cff2-4c88949eeeda"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " Topic Classification using Zero-Shot Learning"
   ],
   "metadata": {
    "id": "qrM33YjDTcPp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "topic_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def classify_topic(text):\n",
    "    labels = [\"Technology\", \"Health\", \"Finance\", \"Education\", \"Entertainment\", \"Politics\", \"Sports\"]\n",
    "    result = topic_classifier(text, candidate_labels=labels)\n",
    "    return result[\"labels\"][0]  # Most relevant topic\n",
    "\n",
    "topic = classify_topic(text)\n",
    "print(\"Detected Topic:\", topic)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244,
     "referenced_widgets": [
      "4b7c058e08e4405284139526fcf246f9",
      "9480516d93044f5cba6967875bc2e8f5",
      "e7e7cc585dd04c72bdb2d8fb9d28bfcb",
      "732ebe1d705f4600a2f6b8b496f8be1e",
      "8f3877f2b8a244c3bc8941f2058f974d",
      "ddaad0d0803a4229ac7550ca5baca264",
      "12b750771c294ce1bec653fee11a6063",
      "320ef588ee9f4a69b71daf8c8e7f0929",
      "cf25f2346fa544d2bf32260ba60d8990",
      "d2af793557ad46199701a662bca1bef7",
      "d04f50ee862e4c8cbb0b20bbb232c8c3",
      "b808f451b8f74e6ca81dfbd52e9746cb",
      "ec58d501684f44f0870da6fa0b49b884",
      "742667652dc048c39f2150667802ee84",
      "730e2d92c10f487884dbd6dcc1742f87",
      "6bb884a7cb3a4fcbaf61295d6d8eb983",
      "5c7a991a5795455695a169442d2d5f69",
      "f51bd687a4aa4e9aa255411065db163c",
      "fa7a4e65f8b0402e87992fa0b88fa14a",
      "c3009113a86d417b8788e00e656d5aad",
      "36342cc6d8dd4457b34e190a043b0ea9",
      "2da2f34d346b47fcb9e01256a62971cc",
      "6ce0676b880b43acaacf3d495cc8c69d",
      "1311c2e0ac044e9cbc62276f3fd03619",
      "895a95c9c6bb434e8e026dc56e2687d4",
      "e4fab1296ed0410682d919c629b90f7f",
      "fcbb16d5d6df4f97a561589b41ea9136",
      "ff08fae3cc504a3d9dbef675132b2160",
      "c4dd850e282b465cbff1d9c68d6f12dc",
      "0f80493f57b94c6ea1fa1c6a7e6d78ed",
      "edc70b470df3475bb68593c3d54716cb",
      "2d791a78e51442afb768db320384af2e",
      "13bdb9d71321483e8f27750881082715",
      "1d069d4d96a144399450be42202bdb56",
      "9d40aa8a2df2441ca99bf49e8ce45cb3",
      "92dd4728fa684967b78b6ff76edb729d",
      "84e181cf9404421ca41fea5fcc9146bd",
      "94cd65e255fe4050b486a24afbc60b33",
      "c2c3dcf473be4976810a984bb60b3ccc",
      "af4335c289ee4f99aa403cf6c6a4b6c0",
      "845ea532ce654970ab18dd8bb846347a",
      "5a786b4572204864bb6c0905dee865e3",
      "e4d94179cd7349339b7109b4a98d192d",
      "1f49ef8b43524f85b50db0c0194681f4",
      "5b208e0dd69545579432352c3f12fa90",
      "580b9bc2c5834093a79a97ce370e323c",
      "58e8cd4003b44b4abbb9e906ab77a434",
      "6f15c55c6fee4409b83a02181bb45f82",
      "ee9346ef082a4bdaa48cb5e88a940992",
      "30d78dca6b134a94b54d6e45beb3fe66",
      "48c9e7661dcb4a638ae11d4c820fdee2",
      "8bc937376d0645d099339425549d264a",
      "59ffa228803144eb8fc836dccd8e0f65",
      "253a246dec5a449b9408eb26fd2b7c3d",
      "388765396d7a44369ca479a113a17b92",
      "18102b2912ce44fda31c25326ff44064",
      "6937fab7e6124bc390eefe6ce0cefba5",
      "ab00bc67814b429f8947c63c29bdc12c",
      "d8fb38a1286445619c28b628c313d45a",
      "f87e624dbacf487ebaea3143bfc460fe",
      "9dfab7cccfcb4b32bf2390f993126e85",
      "0d66958c26c44c6f8c406af865c2e6ef",
      "67156aaa64b64f41b64280961a4e51a2",
      "e23fa613e5404eb9a7c2967f3a091b0b",
      "aa3de97841364fc5b28ac7b413032f7a",
      "1b9901b4e587406aaaa923d4c59ca76c"
     ]
    },
    "id": "3tBNs5DxQNjc",
    "outputId": "3e26eb28-147c-43cf-eb19-e7e01c0c8527"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    " Text Paraphrasing using T5 Model"
   ],
   "metadata": {
    "id": "DsFs34e7ThLs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load paraphrasing model\n",
    "paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
    "\n",
    "def paraphrase_text(text):\n",
    "\n",
    "    result = paraphraser(f\"paraphrase: {text}\", max_length=100, do_sample=False)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Example usage\n",
    "paraphrased = paraphrase_text(\"AI is changing the world by automating tasks.\")\n",
    "print(\"Paraphrased Text:\", paraphrased)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244,
     "referenced_widgets": [
      "5bf21884ea4143dc997398f9f6b2a315",
      "a15e46e2bbaa472b88ee39b615d2f82d",
      "2f3943755f94468997d3b1b6ed439c1f",
      "438f618ad77c45ac91db8097a26343ba",
      "a33c2efc25b047d59ecb02287fc874ff",
      "0188d42e27d445aa9efe41a0a76a76d2",
      "8125e3f8f1ad4b54aa518dff41fb38b4",
      "ed5579607d1045cdbed28e5e4174ae78",
      "c718eb5384f945d2a6bac5de161ff9c3",
      "00f4b4b3d9b04fa39d56ac9fbe882092",
      "21c632b8b8754928969bc4129bd4ea26",
      "b45fbe63a01a4789869fd9395376923a",
      "f29a37d877d54c3587fc3da4c102ab83",
      "6bfd61c75e42486b8e747cb01bb308fb",
      "db2d466957314901a6813bd6d88f63df",
      "12bad374ba1342e089612556c4e53adf",
      "2fbc192fdf9343e8a40c57de950bce09",
      "51fd3114b1354d789f18024bc0d0bd38",
      "3d2d039a795a4abe9c6edaaca36c17c6",
      "222618d94add415392a5c5fa817591f6",
      "74f295ff99b54518968621ce435991fe",
      "a86b84a722ba46fd8aa7a94ce78c3a99",
      "98117de54e764f63bdb1408582141feb",
      "37bd3fb0b72a47988e4582b46c3eb1bb",
      "2938fe2b3c3a4690abad82441ed6416b",
      "10a668699edf41508f11b06937359907",
      "c00a475e25414944b0870ec6444f9018",
      "accc76715e0f48edbca3ad91d07b7bf8",
      "5c296e4ac1364ca2b9abb8706409b2b3",
      "193cd177f2574d2785f59aa24bd8646f",
      "57b813c3d175430aa35b6cf5a09e4698",
      "eaf4b32d8d9f4aca82c33ac615c0bad5",
      "69ad89e6523d4ada834ea4ff58745c60",
      "c11ef0a065184c3e8f9a40835d889787",
      "7563be10a5bd47b2b0c659e15f9bd423",
      "db7a479798864f4bbc661a8458c7e33c",
      "b63758cb62294a2f8e79f35803715e1d",
      "3f8c9cc181ce40c3a0fe5d649de4ec98",
      "3823f46278ce42d3b33000d011420404",
      "8f604999638549c8879537158c72b906",
      "fff7a07b8b814054a80ae50263b61bc1",
      "3ff5cd10b7094cacba939859f6c69a02",
      "f166f9f0b4f546bc9899f58cad0b072f",
      "60f176c4cbb546c488fa13bb45affe99",
      "ae75a3d2ef384eb1bd84beee24788122",
      "dde791f2e24b4ae99962410df9621679",
      "2697209cd232404b97451682ceeb8054",
      "74a6bed63ed54b0f9f9761f94db9d824",
      "a9042cb8fcf74d5999e9f975a23d0405",
      "16b6f009b686488188ece2d869946323",
      "47152b16a78b43ab84c9c6354f5ddd37",
      "7fe73fd3ee7b4ac486c5dd63cd327b76",
      "ee5d1997e3a442ea9f27ed35c3519070",
      "5eeb6dbeaeae494890dfac696f5a4fbf",
      "d399e2cabbc3433ebc08b8c015a1c453",
      "d1c065c5b2574d30b1bd812ee9415af1",
      "d6a90aad30d34fdc9472cf590ad00887",
      "3719f431a58b414db2de42415fd053a5",
      "69fe4581e56f4e2ead2e302f50de4555",
      "42ac8ba57966497f9b375cd4a9bcac4b",
      "06dd99a2ea0f457383a2d29971840591",
      "6fcb2551d60146dc8e6c9f8e53230813",
      "2e2546416df2427b83147cbf9d8070b1",
      "d07521e3aa8a438fa356aa2456572980",
      "d5191a443d6c4155a49be06844f18f7d",
      "5942529f7e9e45e695e20ced0b01bcfb"
     ]
    },
    "id": "wNsnkkcoQ3t7",
    "outputId": "ccdd166f-2198-4da1-a494-a8c0c8fc81af"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install textstat"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsMn4UHSRIKf",
    "outputId": "055b1273-af29-406a-9f9a-f689d04c672e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Readability Analysis using TextStat\n"
   ],
   "metadata": {
    "id": "B-9IHZQPToXu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import textstat\n",
    "\n",
    "def get_readability_score(text):\n",
    "    \"\"\"Get Flesch reading ease score.\"\"\"\n",
    "    score = textstat.flesch_reading_ease(text)\n",
    "    return f\"Readability Score: {score} (Higher = Easier to Read)\"\n",
    "\n",
    "\n",
    "score = get_readability_score(text)\n",
    "print(score)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Y-RAaOcRBEe",
    "outputId": "a7135456-e451-4319-d632-5f4f3cf88294"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Automatic Question Generation using T5 Model"
   ],
   "metadata": {
    "id": "qPw3QfEOTy9L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "question_generator = pipeline(\"text2text-generation\", model=\"t5-large\")\n",
    "\n",
    "def generate_questions(summary):\n",
    "    \"\"\"Generate a better question from the summary.\"\"\"\n",
    "    prompt = f\"Generate a question based on this text: {summary}\"\n",
    "    result = question_generator(prompt, max_length=50, do_sample=True)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Example usage\n",
    "\n",
    "question = generate_questions(text)\n",
    "print(\"Generated Question:\", question)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232,
     "referenced_widgets": [
      "3de2fc74de9d4f5885d09ce7dc335445",
      "7095b6bf75ce46ab92f8929ae0d02b06",
      "358e0a53a3fd49feb2f9f117267119e7",
      "e1b55792496f4461a032413f3edcbf9f",
      "d5d463fab2d74e6884be4528d0c5d624",
      "0b03c8504b83447a9be612f4556a2250",
      "0762930f345446c7bcdc7043768c029d",
      "1fbb8c86bcf5464b946dbf2eab12c639",
      "d0104d09b9c04102a2f6c85c30ddfa11",
      "71433326a0504ab6878939b647232257",
      "bca1e494aab94f88baaa0f947f52327e",
      "2f9a47ed3ef744ad93213b3792a7cd48",
      "67e255d765624abf964fc5ea428065a7",
      "cf1f33fd7c1a4cd6b9899de22c81b15f",
      "1bc7b9c209444651a7f5669c5a15e091",
      "532d3eed20e04432ab355737a00b171a",
      "972e1b4b9dc047d7afec4e355a37a9f3",
      "18ced4c18afe4452bf37369f4cf1c6b5",
      "bf41947996854a27a004f697f891caa7",
      "a3feccdcb09a455cb27945b4060624b2",
      "95075380020d434099bac55cfba5dd78",
      "41285dc9df684175b5aca82e410d77f6",
      "03f61300547a484aa33e4f7f9d6b0e0a",
      "62fe28b8b7cd4dcbb95cac95d1b82465",
      "e0e62e9aabfd40c090b41365a9c92613",
      "6c3f003730e742f7a204121d59aac0c3",
      "df543312291c40c58e9feaa4238f10d4",
      "3fcf8d3af0a64cf983661be57f6d9997",
      "88d8405988e740e98de9a9fd994c2f68",
      "37a1f524409c4d598e737ba6bbb0af47",
      "52e4b1e1bc51416fba5b426dffe8832c",
      "cabecb21dd534c038844f9c785529d88",
      "d876a9669acc446fadbc72680eda4eb4",
      "42abf946f73d49a682db9104ecc7c28d",
      "de3aef1b17264de7912210725792d1d0",
      "42d818b5acba4dcda2201d37ce9753be",
      "18c1bb725ebb4ca0aaad6a9abfc4700a",
      "9429c0270ca14e7abaca227b581f68b8",
      "4566f72425994a09974f69b0fd1b06f5",
      "eb557dad897b494fb2b76c8d895402ee",
      "992076b026d743679bd9bb1a399d42f5",
      "9633b48ad5b644969d7be99807598ae8",
      "b677392354c84e26a03861a861bf06b9",
      "49ff8c05b0354bff82314a97538afb63",
      "90b70995d0374c93a2d384d008b97192",
      "b10c4dfe90b44978bee553a8670f225e",
      "391e0110bf884f02984b9a43c483b505",
      "56e0541041ab4a4c80e39ac87d9b934f",
      "8b87903083674665afeb770158d19f66",
      "d15175d0013d491085d7f6a0cc7e6f44",
      "22f36f9613534cb985bb902925311125",
      "168fd4f4ceec4cb0a473ebd83c619d0d",
      "19b31d7f7c654105a696c876642ee5e1",
      "2fb0f6f4adff46b582ee18c201a753cf",
      "f2efe327b21344469707317c5da54dcf"
     ]
    },
    "id": "qPO8dCNbRX14",
    "outputId": "48507088-8e42-4791-a9b9-c54ba5a40ae1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualizing Topic Classification Results"
   ],
   "metadata": {
    "id": "8ASO7IALUgI2"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_topic_distribution(topic):\n",
    "    \"\"\"Display topic classification results as a pie chart.\"\"\"\n",
    "    topic_data = {topic: 1}  # Only one topic per input\n",
    "    plt.pie(topic_data.values(), labels=topic_data.keys(), autopct=\"%1.1f%%\", colors=[\"skyblue\"])\n",
    "    plt.title(\"Detected Topic Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_topic_distribution(topic)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "XtjMwX2PUlrd",
    "outputId": "c6c7f0f2-9d43-4958-ad37-ec6f1b42b96a"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluating Summary Quality with ROUGE Score"
   ],
   "metadata": {
    "id": "_TSPzOr5U-Ab"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def evaluate_summary(reference, generated):\n",
    "    \"\"\"Calculate ROUGE score between reference text and generated summary.\"\"\"\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "\n",
    "    for key, value in scores.items():\n",
    "        print(f\"{key}: Precision={value.precision:.4f}, Recall={value.recall:.4f}, F1-Score={value.fmeasure:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "evaluate_summary(text, summary)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCoFPvzpUxdo",
    "outputId": "be4f6a99-e46d-4507-920b-b2820c4c5ef6"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
